# PowerInfer with ROCm 6.4.4 for AMD Strix Halo (gfx1151)
# Using working configuration from eh-ops-repo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: powerinfer
  namespace: llama-cpp
  labels:
    app: powerinfer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: powerinfer
  template:
    metadata:
      labels:
        app: powerinfer
    spec:
      nodeSelector:
        workload-type: gpu
      tolerations:
        - key: workload-type
          operator: Equal
          value: heavy
          effect: NoSchedule
      containers:
        - name: powerinfer
          image: ghcr.io/cecil-the-coder/powerinfer-strix-halo-rocm:latest
          imagePullPolicy: Always
          command:
            - /app/server
          args:
            - --model
            - /models/ReluLLaMA-7B-PowerInfer-GGUF/llama-7b-relu.powerinfer.gguf
            - --ctx-size
            - "4096"
            - --n-gpu-layers
            - "-1"
            - --host
            - "0.0.0.0"
            - --port
            - "8080"
          env:
            # ROCm 6.4.4 configuration matching eh-ops-repo working setup
            - name: ROCM_PATH
              value: /opt/rocm
            - name: HIP_PATH
              value: /opt/rocm
            - name: HSA_OVERRIDE_GFX_VERSION
              value: "11.5.1"
            - name: ROCBLAS_USE_HIPBLASLT
              value: "1"
            - name: LLAMA_HIP_UMA
              value: "ON"
          ports:
            - containerPort: 8080
              name: http
          volumeMounts:
            - name: models
              mountPath: /models
            - name: dev-kfd
              mountPath: /dev/kfd
            - name: dev-dri
              mountPath: /dev/dri
          securityContext:
            capabilities:
              add:
                - SYS_PTRACE
            seccompProfile:
              type: Unconfined
          resources:
            limits:
              memory: 80Gi
            requests:
              cpu: "4"
              memory: 16Gi
      volumes:
        - name: models
          persistentVolumeClaim:
            claimName: llama-models
        - name: dev-kfd
          hostPath:
            path: /dev/kfd
        - name: dev-dri
          hostPath:
            path: /dev/dri
---
apiVersion: v1
kind: Service
metadata:
  name: powerinfer
  namespace: llama-cpp
spec:
  selector:
    app: powerinfer
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  type: ClusterIP
