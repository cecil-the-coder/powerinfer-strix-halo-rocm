# PowerInfer CPU-only (ROCm disabled due to gfx1151 memory faults)
# TODO: Re-enable GPU when ROCm properly supports Strix Halo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: powerinfer
  namespace: llama-cpp
  labels:
    app: powerinfer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: powerinfer
  template:
    metadata:
      labels:
        app: powerinfer
    spec:
      nodeSelector:
        workload-type: gpu
      tolerations:
        - key: workload-type
          operator: Equal
          value: heavy
          effect: NoSchedule
      containers:
        - name: powerinfer
          image: ghcr.io/cecil-the-coder/powerinfer-strix-halo-rocm:latest
          imagePullPolicy: Always
          command:
            - /app/server
          args:
            - --model
            - /models/ReluLLaMA-7B-PowerInfer-GGUF/llama-7b-relu.powerinfer.gguf
            - --ctx-size
            - "4096"
            - --threads
            - "32"
            - --host
            - "0.0.0.0"
            - --port
            - "8080"
          ports:
            - containerPort: 8080
              name: http
          volumeMounts:
            - name: models
              mountPath: /models
          resources:
            limits:
              memory: 64Gi
            requests:
              memory: 16Gi
      volumes:
        - name: models
          persistentVolumeClaim:
            claimName: llama-models
---
apiVersion: v1
kind: Service
metadata:
  name: powerinfer
  namespace: llama-cpp
spec:
  selector:
    app: powerinfer
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  type: ClusterIP
